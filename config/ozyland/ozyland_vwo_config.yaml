%YAML:1.0

imu: 0
wheel: 1
only_initial_with_wheel: 0  # Whether to use only wheels for initialization (no factor graph aided)
plane: 0
num_of_cam: 1

imu_topic: "/imu"
wheel_topic: "/odom"
image0_topic: "/camera/image_raw"
image1_topic: "/camera/image_raw"
output_path: "/home/wfram/viw_fusion_ws/src/VIW-Fusion/output"

cam0_calib: "ozyland.yaml"
cam1_calib: "ozyland.yaml"
image_width: 640
image_height: 480

# Extrinsic parameter between IMU and Camera
estimate_extrinsic: 0

extrinsic_type: 3 # 0: ALL 1: Only translation 2: Only Rotation 3: no z 4: no rotation and no z

# TODO
body_T_cam0: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [ 0.,  0.,  1., 0.42,
           -1.,  0.,  0., 0.0,
           0., -1.,  0., 1.75,
           0., 0., 0., 1. ]

body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [0.0375876, 0.0190846, 0.9991111, -0.0063742,
          -0.9990644, -0.0206830, 0.0379809, -0.1263024,
          0.0213895, -0.9996039, 0.0182893, 0.0288205,
          0., 0., 0., 1.]

# Extrinsic parameter between IMU and Wheel.
estimate_wheel_extrinsic: 0

extrinsic_type_wheel: 3 # 0: ALL 1: Only translation 2: Only Rotation 3: no z 4: no rotation and no z

#wheel to body
body_T_wheel: !!opencv-matrix
  rows: 4
  cols: 4
  dt: d
  data: [1.0, 0.0, 0.0, 0.0,
         0.0, 1.0, 0.0, 0.0,
         0.0, 0.0, 1.0, 0.0,
         0., 0., 0., 1]

#plane noise
#mono:0.01 stereo:0.005
roll_n: 0.01 # 0.01
#mono:0.01  stereo:0.005
pitch_n: 0.01 # 0.01
#mono:0.05 stereo:0.025
zpw_n: 0.05 # 0.05

#Multiple thread support
multiple_thread: 1

#feature traker paprameters
max_cnt: 150            # max feature number in feature tracking
min_dist: 30            # min distance between two features 
freq: 30                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)

#imu parameters       The more accurate parameters you provide, the better performance
acc_n: 0.04641977329563476         # accelerometer measurement noise standard deviation. #0.2   0.04
gyr_n: 0.013213877349668923        # gyroscope measurement noise standard deviation.     #0.05  0.004
acc_w: 0.0019703618139556927         # accelerometer bias random work noise standard deviation.  #0.002
gyr_w: 2.206282069791498e-05       # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.805 # 9.805 9.81007        # gravity magnitude

#wheel parameters
# rad/s mono:0.004 stereo:0.002
wheel_gyro_noise_sigma: 0.004 # 0.004 0.003
#ã€€m/s mono:0.01  stereo:0.006
wheel_velocity_noise_sigma: 0.01 # 0.01 0.004

estimate_wheel_intrinsic: 0

# wheel intrinsic
sx: 1.0 # 1.0
sy: 1.0 # 1.0
sw: 1.0 # 1.0 0.005

#unsynchronization parameters
estimate_td: 0                      # online estimate time offset between camera and imu
td: 0.00                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#unsynchronization parameters
estimate_td_wheel: 0                      # online estimate time offset between camera and wheel
td_wheel: 0.00                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#loop closure parameters
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "/home/wfram/viw_fusion_ws/src/VINS-Fusion/output/pose_graph" # save and load path
save_image: 0                   # save image in pose graph for visualization prupose; you can close this function by setting 0 
